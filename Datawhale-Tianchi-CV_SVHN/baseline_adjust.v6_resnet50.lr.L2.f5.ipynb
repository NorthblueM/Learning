{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5折，训练五个模型，投票决定每个位置的数字\n",
    "* 学习率：每上升两次测试集loss，学习率减半\n",
    "* L2正则=0.01\n",
    "* 使用resnet50\n",
    "* 验证集和测试集也数据增强，tta=5\n",
    "* epoch=50，预测时选用验证集acc最优的模型（一方面添加正则收敛慢，resnet50收敛慢）\n",
    "* 如果五个模型预测的一个位置的值都不同，则选取第一折的预测值\n",
    "## L2正则=0.1在resnet50上欠拟合\n",
    "* epoch50，验证集上的正确率还在0.5左右，且验证集的loss基本没有上升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline思路\n",
    "\n",
    "将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证，具体包括以下几个步骤：     \n",
    "                   \n",
    "- 赛题数据读取（封装为Pytorch的Dataset和DataLoder）\n",
    "             \n",
    "- 构建CNN模型（使用Pytorch搭建）\n",
    "              \n",
    "- 模型训练与验证\n",
    "                \n",
    "- 模型结果预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  运行环境及安装示例   \n",
    "- 运行环境要求：Python2/3，Pytorch1.x，内存4G，有无GPU都可以。         \n",
    "                        \n",
    "下面给出python3.7+ torch1.3.1gpu版本的环境安装示例：      \n",
    "                               \n",
    "- 首先在Anaconda中创建一个专门用于本次天池练习赛的虚拟环境。          \n",
    "\n",
    ">$conda create -n py37_torch131 python=3.7      \n",
    "                                \n",
    "- 激活环境，并安装pytorch1.3.1\n",
    "                                     \n",
    ">$source activate py37_torch131                         \n",
    "\n",
    ">$conda install pytorch=1.3.1 torchvision cudatoolkit=10.0                     \n",
    "       \n",
    "       \n",
    "- 通过下面的命令一键安装所需其它依赖库     \n",
    "\n",
    ">$pip install jupyter tqdm opencv-python matplotlib pandas                                  \n",
    "       \n",
    "- 启动notebook，即可开始baseline代码的学习                  \n",
    "\n",
    ">$jupyter-notebook    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入常用的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1：定义读取图像的Dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 设置最长的字符长度为5个\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2：定义训练数据和验证数据的Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为有tta，验证集，测试集，采用同一个\n",
    "def data_loader(data_path, data_label):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        SVHNDataset(data_path, data_label,\n",
    "                    transforms.Compose([\n",
    "                        transforms.Resize((64, 128)),\n",
    "                        transforms.RandomCrop((60, 120)),\n",
    "                        transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                        transforms.RandomRotation(5),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])), \n",
    "        batch_size=200, #默认40 \n",
    "        shuffle=False, \n",
    "        num_workers=0, # win下num_works改为0,linux=10\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "val_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "train_val_path = train_path + val_path\n",
    "train_val_label = train_label + val_label\n",
    "print(len(train_val_path), len(train_val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3：定义字符分类模型\n",
    "使用resnet18的模型作为特征提取模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "                \n",
    "        model_conv = models.resnet50(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 11)\n",
    "        self.fc2 = nn.Linear(2048, 11)\n",
    "        self.fc3 = nn.Linear(2048, 11)\n",
    "        self.fc4 = nn.Linear(2048, 11)\n",
    "        self.fc5 = nn.Linear(2048, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4：定义训练、验证和预测模块 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        c0, c1, c2, c3, c4 = model(input)\n",
    "        target = target.long() #添加\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "                criterion(c1, target[:, 1]) + \\\n",
    "                criterion(c2, target[:, 2]) + \\\n",
    "                criterion(c3, target[:, 3]) + \\\n",
    "                criterion(c4, target[:, 4])\n",
    "        \n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if i % 5 == 0:\n",
    "            # print(loss.item())\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            target = target.long() #添加\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                    criterion(c1, target[:, 1]) + \\\n",
    "                    criterion(c2, target[:, 2]) + \\\n",
    "                    criterion(c3, target[:, 3]) + \\\n",
    "                    criterion(c4, target[:, 4])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    \n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                \n",
    "                c0, c1, c2, c3, c4 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(), \n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(), \n",
    "                        c3.data.cpu().numpy(),\n",
    "                        c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(), \n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(), \n",
    "                        c3.data.numpy(),\n",
    "                        c4.data.numpy()], axis=1)\n",
    "                \n",
    "                test_pred.append(output)\n",
    "        \n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5：迭代训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一折的数据\n",
    "map_folder_path = {}\n",
    "map_folder_label = {}\n",
    "folder_len = len(train_val_path)/folder_k\n",
    "\n",
    "for i_k in range(folder_k):\n",
    "    map_folder_path[i_k] = train_val_path[int(i_k*folder_len):int((i_k+1)*folder_len)]\n",
    "    map_folder_label[i_k] = train_val_label[int(i_k*folder_len):int((i_k+1)*folder_len)]\n",
    "\n",
    "# 每一折的训练集和验证集\n",
    "map_train_path = {}\n",
    "map_train_label = {}\n",
    "map_val_path = {}\n",
    "map_val_label = {}\n",
    "for i_k in range(folder_k):\n",
    "    val_k = folder_k - i_k - 1\n",
    "    map_train_path[i_k] = []\n",
    "    map_train_label[i_k] = []\n",
    "    map_val_path[i_k] = map_folder_path[val_k]\n",
    "    map_val_label[i_k] = map_folder_label[val_k]\n",
    "    for i in range(folder_k):\n",
    "        if i != val_k:\n",
    "            map_train_path[i_k].extend(map_folder_path[i])\n",
    "            map_train_label[i_k].extend(map_folder_label[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "for i_k in range(folder_k):\n",
    "    print('folder:\\t%d'%i_k)\n",
    "\n",
    "    train_loader = data_loader(map_train_path[i_k], map_train_label[i_k])\n",
    "    val_loader = data_loader(map_val_path[i_k], map_val_label[i_k])\n",
    "\n",
    "    model = SVHN_Model1()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lr = 0.001\n",
    "    wd = 0.1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=wd)\n",
    "    \n",
    "    epoch_total = 50\n",
    "    val_tta = 5\n",
    "\n",
    "    use_cuda = True\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "\n",
    "    best_loss = 1000.0\n",
    "    best_acc = 0\n",
    "\n",
    "    loss_increase_num = 0 # 用于调节学习率\n",
    "    val_loss_last = best_loss # 上一次的验证集误差\n",
    "\n",
    "\n",
    "    for epoch in range(epoch_total):\n",
    "        train_loss = train(train_loader, model, criterion, optimizer)\n",
    "        val_loss = validate(val_loader, model, criterion)\n",
    "    \n",
    "        val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "        val_predict_label = predict(val_loader, model, val_tta)\n",
    "        val_predict_label = np.vstack([\n",
    "            val_predict_label[:, :11].argmax(1),\n",
    "            val_predict_label[:, 11:22].argmax(1),\n",
    "            val_predict_label[:, 22:33].argmax(1),\n",
    "            val_predict_label[:, 33:44].argmax(1),\n",
    "            val_predict_label[:, 44:55].argmax(1),\n",
    "        ]).T\n",
    "        val_label_pred = []\n",
    "        for x in val_predict_label:\n",
    "            val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "        val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "    \n",
    "        print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "        print('Val char acc:\\t%f'%val_char_acc)\n",
    "    \n",
    "        # 修改学习率，如果验证集的loss出现上升\n",
    "        if epoch != 1 and val_loss > val_loss_last:\n",
    "            loss_increase_num += 1\n",
    "            if loss_increase_num == 2: # 出现上升两次\n",
    "                loss_increase_num = 0\n",
    "                if lr > 0.000011: # 不能过小\n",
    "                    lr = lr * 0.5\n",
    "                print('learning rate:\\t%f'%lr)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=wd)\n",
    "\n",
    "        val_loss_last = val_loss\n",
    "\n",
    "        # 记录下验证集精度，保存两个，一个loss最优，一个acc最优\n",
    "        save_model_loss_name = 'model_v6_' + str(i_k) + '_loss.pt'\n",
    "        save_model_acc_name = 'model_v6_' + str(i_k) + '_acc.pt'\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//'+save_model_loss_name)\n",
    "        if val_char_acc > best_acc:\n",
    "            best_acc = val_char_acc\n",
    "            torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//'+save_model_acc_name)\n",
    "    \n",
    "    # 保存最后训练完的模型\n",
    "    save_model_epoch_name = 'model_v6_'+str(i_k)+'_epoch'+str(epoch_total)+'.pt'\n",
    "    torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//'+save_model_epoch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练两个2 Epoch后，输出的训练日志为：\n",
    "         \n",
    "Epoch: 0, Train loss: 3.1 \t Val loss: 3.4 验证集精度：0.3439       \n",
    "Epoch: 1, Train loss: 2.1 \t Val loss: 2.9 验证集精度：0.4346\n",
    "\n",
    "* Quadro P1000: batch_size=40 epoch=2 需要6min15s GPU-util:50%-60%\n",
    "* Quadro P1000: batch_size=200 epoch=2 需要4min59s GPU-util:60%-98%\n",
    "* i7-8850H: batch_size=40 epoch=2 需要47min30s CPU-util:50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤6：对测试集样本进行预测，生成提交文件          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tta = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取各个模型\n",
    "map_model = {}\n",
    "for i_k in range(folder_k):\n",
    "    model = SVHN_Model1()\n",
    "\n",
    "    use_cuda = True\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    save_model_acc_name = 'model_v6_' + str(i_k) + '_acc.pt'\n",
    "    model.load_state_dict(torch.load('../../data/Datawhale-Tianchi-CV_SVHN//'+save_model_acc_name))\n",
    "\n",
    "    map_model[i_k] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_test_a/*.png')\n",
    "# test_path.sort()\n",
    "# test_label = [[1]] * len(test_path)\n",
    "# print(len(test_path), len(test_label))\n",
    "\n",
    "# test_loader = data_loader(test_path, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用验证集测试\n",
    "test_path = val_path\n",
    "test_path.sort()\n",
    "test_label = val_label\n",
    "print(len(test_path), len(test_label))\n",
    "\n",
    "test_loader = data_loader(test_path, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个模型预测\n",
    "map_test_predict_label_org = {}\n",
    "map_test_predict_label = {}\n",
    "\n",
    "for i_k in range(folder_k):\n",
    "    test_predict_label_org = predict(test_loader, map_model[i_k], test_tta)\n",
    "\n",
    "    test_predict_label = np.vstack([\n",
    "        test_predict_label_org[:, :11].argmax(1),\n",
    "        test_predict_label_org[:, 11:22].argmax(1),\n",
    "        test_predict_label_org[:, 22:33].argmax(1),\n",
    "        test_predict_label_org[:, 33:44].argmax(1),\n",
    "        test_predict_label_org[:, 44:55].argmax(1),\n",
    "    ]).T\n",
    "\n",
    "    map_test_predict_label_org[i_k] = test_predict_label_org\n",
    "    map_test_predict_label[i_k] = test_predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行是每个模型，列是每个位置字符\n",
    "def vote_label(label_folder):\n",
    "    label = []\n",
    "    df_label_folder = pd.DataFrame(label_folder)\n",
    "    for i_col in range(df_label_folder.shape[1]):\n",
    "        label.append(df_label_folder.iloc[:,i_col].value_counts().idxmax())\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 投票\n",
    "test_predict_label = []\n",
    "for i_row in range(map_test_predict_label[0].shape[0]):\n",
    "    label_folder = []\n",
    "    for i_k in range(folder_k):\n",
    "        label_folder.append(list(map_test_predict_label[i_k][i_row]))\n",
    "    \n",
    "    test_predict_label.append(vote_label(label_folder))\n",
    "\n",
    "test_predict_label = np.vstack(test_predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_pred = []\n",
    "    for x in test_predict_label:\n",
    "        test_label_pred.append(''.join(map(str, x[x!=10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用验证集测试\n",
    "val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "print(val_char_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_submit = pd.read_csv('../../data/Datawhale-Tianchi-CV_SVHN/mchar_sample_submit_A.csv')\n",
    "# df_submit['file_code'] = test_label_pred\n",
    "# df_submit.to_csv('../../data/Datawhale-Tianchi-CV_SVHN/resnet18_baseline_v6_valAccMax.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练完成2个Epoch后，模型在测试集上的成绩应该在0.33左右。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitbb390991d78f474893554122ad84e457"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
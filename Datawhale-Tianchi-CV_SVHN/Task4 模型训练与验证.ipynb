{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4 模型训练与验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个成熟合格的深度学习训练流程至少具备以下功能：       \n",
    "\n",
    "- 在训练集上进行训练，并在验证集上进行验证；      \n",
    "- 模型可以保存最优的权重，并读取权重；      \n",
    "- 记录下训练集和验证集的精度，便于调参。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 构造验证集\n",
    "\n",
    "在机器学习模型（特别是深度学习模型）的训练过程中，模型是非常容易过拟合的。深度学习模型在不断的训练过程中训练误差会逐渐降低，但测试误差的走势则不一定。       \n",
    "          \n",
    "在模型的训练过程中，模型只能利用训练数据来进行训练，模型并不能接触到测试集上的样本。因此模型如果将训练集学的过好，模型就会记住训练样本的细节，导致模型在测试集的泛化效果较差，这种现象称为过拟合（Overfitting）。与过拟合相对应的是欠拟合（Underfitting），即模型在训练集上的拟合效果较差。           \n",
    "      \n",
    "![IMG](IMG/Task04/loss.png)    \n",
    "    \n",
    "如图所示：随着模型复杂度和模型训练轮数的增加，CNN模型在训练集上的误差会降低，但在测试集上的误差会逐渐降低，然后逐渐升高，而我们为了追求的是模型在测试集上的精度越高越好。         \n",
    "       \n",
    "导致模型过拟合的情况有很多种原因，其中最为常见的情况是模型复杂度（Model Complexity ）太高，导致模型学习到了训练数据的方方面面，学习到了一些细枝末节的规律。       \n",
    "      \n",
    "解决上述问题最好的解决方法：构建一个与测试集尽可能分布一致的样本集（可称为验证集），在训练过程中不断验证模型在验证集上的精度，并以此控制模型的训练。       \n",
    "        \n",
    "在给定赛题后，赛题方会给定训练集和测试集两部分数据。参赛者需要在训练集上面构建模型，并在测试集上面验证模型的泛化能力。因此参赛者可以通过提交模型对测试集的预测结果，来验证自己模型的泛化能力。同时参赛方也会限制一些提交的次数限制，以此避免参赛选手“刷分”。       \n",
    "      \n",
    "在一般情况下，参赛选手也可以自己在本地划分出一个验证集出来，进行本地验证。训练集、验证集和测试集分别有不同的作用：\n",
    "\n",
    "- 训练集（Train Set）：模型用于训练和调整模型参数；\n",
    "- 验证集（Validation Set）：用来验证模型精度和调整模型超参数；\n",
    "- 测试集（Test Set）：验证模型的泛化能力。\n",
    "       \n",
    "因为训练集和验证集是分开的，所以模型在验证集上面的精度在一定程度上可以反映模型的泛化能力。在划分验证集的时候，需要注意**验证集的分布应该与测试集尽量保持一致**，不然模型在验证集上的精度就失去了指导意义。 \n",
    "       \n",
    "既然验证集这么重要，那么如何划分本地验证集呢。在一些比赛中，赛题方会给定验证集；如果赛题方没有给定验证集，那么参赛选手就需要从训练集中拆分一部分得到验证集。验证集的划分有如下几种方式：       \n",
    "\n",
    "![IMG](IMG/Task04/验证集构造.png)                 \n",
    "\n",
    "- #### 留出法（Hold-Out）           \n",
    "直接将训练集划分成两部分，新的训练集和验证集。这种划分方式的优点是最为直接简单；缺点是只得到了一份验证集，有可能导致模型在验证集上过拟合。**留出法应用场景是数据量比较大的情况。**     \n",
    "      \n",
    "- #### 交叉验证法（Cross Validation，CV）      \n",
    "将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。这种划分方式是所有的训练集都是验证集，最终模型验证精度是K份平均得到。这种方式的优点是验证集精度比较可靠，训练K次可以得到K个有多样性差异的模型；**CV验证的缺点是需要训练K次，不适合数据量很大的情况。**     \n",
    "      \n",
    "- #### 自助采样法（BootStrap）      \n",
    "通过有放回的采样方式得到新的训练集和验证集，每次的训练集和验证集都是有区别的。**这种划分方式一般适用于数据量较小的情况。**      \n",
    "             \n",
    "在本次赛题中已经划分为验证集，因此选手可以直接使用训练集进行训练，并使用验证集进行验证精度（当然你也可以合并训练集和验证集，自行划分验证集）。   \n",
    "           \n",
    "当然这些划分方法是从数据划分方式的角度来讲的，在现有的数据比赛中一般采用的划分方法是留出法和交叉验证法。如果数据量比较大，留出法还是比较合适的。当然任何的验证集的划分得到的验证集都是要保证训练集-验证集-测试集的分布是一致的，所以如果不管划分何种的划分方式都是需要注意的。\n",
    "            \n",
    "这里的分布一般指的是与标签相关的统计分布，比如在分类任务中“分布”指的是标签的类别分布，训练集-验证集-测试集的类别分布情况应该大体一致；**如果标签是带有时序信息，则验证集和测试集的时间间隔应该保持一致。**           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 模型训练与验证 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构造训练集和验证集；\n",
    "- 每轮进行训练和验证，并根据最优验证集精度保存模型。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 设置最长的字符长度为5个\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train/*.png') #glob.glob 返回所有匹配的文件路径列表。\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=100, #默认40 \n",
    "    shuffle=True, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")\n",
    "\n",
    "val_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=100, #默认40 \n",
    "    shuffle=False, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "                \n",
    "        model_conv = models.resnet18(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 11)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "        self.fc3 = nn.Linear(512, 11)\n",
    "        self.fc4 = nn.Linear(512, 11)\n",
    "        self.fc5 = nn.Linear(512, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中每个Epoch的训练：     \n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        c0, c1, c2, c3, c4 = model(data[0])\n",
    "        target = target.long() #添加\n",
    "        loss = criterion(c0, data[1][:, 0]) + \\\n",
    "                criterion(c1, data[1][:, 1]) + \\\n",
    "                criterion(c2, data[1][:, 2]) + \\\n",
    "                criterion(c3, data[1][:, 3]) + \\\n",
    "                criterion(c4, data[1][:, 4]) + \\\n",
    "\n",
    "        loss /= 5\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中每个Epoch的验证\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            c0, c1, c2, c3, c4 = model(data[0])\n",
    "            loss = criterion(c0, data[1][:, 0]) + \\\n",
    "                    criterion(c1, data[1][:, 1]) + \\\n",
    "                    criterion(c2, data[1][:, 2]) + \\\n",
    "                    criterion(c3, data[1][:, 3]) + \\\n",
    "                    criterion(c4, data[1][:, 4]) + \\\n",
    "\n",
    "            loss /= 5\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss (size_average=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "best_loss = 1000.0\n",
    "\n",
    "for epoch in range(2):\n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    \n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN/model_task4.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 模型保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Pytorch中模型的保存和加载非常简单，比较常见的做法是保存和加载模型参数：        \n",
    "       ``` torch.save(model_object.state_dict(), 'model.pt') ```            \n",
    "       ``` model.load_state_dict(torch.load(' model.pt')) ``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 模型调参流程  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习原理少但实践性非常强，基本上很多的模型的验证只能通过训练来完成。同时深度学习有众多的网络结构和超参数，因此需要反复尝试。训练深度学习模型需要GPU的硬件支持，也需要较多的训练时间，如何有效的训练深度学习模型逐渐成为了一门学问。\n",
    "             \n",
    "深度学习有众多的训练技巧，比较推荐的阅读链接有：          \n",
    "- http://www.lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html      \n",
    "- http://karpathy.github.io/2019/04/25/recipe/     \n",
    "         \n",
    "本节挑选了常见的一些技巧来讲解，并针对本次赛题进行具体分析。与传统的机器学习模型不同，深度学习模型的精度与模型的复杂度、数据量、正则化、数据扩增等因素直接相关。所以当深度学习模型处于不同的阶段（欠拟合、过拟合和完美拟合）的情况下，大家可以知道可以什么角度来继续优化模型。                 \n",
    "                \n",
    "在参加本次比赛的过程中，我建议大家以如下逻辑完成：      \n",
    "        \n",
    "- 1.初步构建简单的CNN模型，不用特别复杂，跑通训练、验证和预测的流程；    \n",
    "                \n",
    "- 2.简单CNN模型的损失会比较大，尝试增加模型复杂度，并观察验证集精度；            \n",
    "             \n",
    "- 3.在增加模型复杂度的同时增加数据扩增方法，直至验证集精度不变。\n",
    "            \n",
    "![IMG](IMG/Task04/调参流程.png)           \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是模型复杂度是相对的，并不一定模型越复杂越好。在有限设备和有限时间下，需要选择能够快速迭代训练的模型。 "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
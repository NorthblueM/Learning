{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集也进行数据增强，有一点点点效果\n",
    "val tta=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline思路\n",
    "\n",
    "将不定长字符转换为定长字符的识别问题，并使用CNN完成训练和验证，具体包括以下几个步骤：     \n",
    "                   \n",
    "- 赛题数据读取（封装为Pytorch的Dataset和DataLoder）\n",
    "             \n",
    "- 构建CNN模型（使用Pytorch搭建）\n",
    "              \n",
    "- 模型训练与验证\n",
    "                \n",
    "- 模型结果预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  运行环境及安装示例   \n",
    "- 运行环境要求：Python2/3，Pytorch1.x，内存4G，有无GPU都可以。         \n",
    "                        \n",
    "下面给出python3.7+ torch1.3.1gpu版本的环境安装示例：      \n",
    "                               \n",
    "- 首先在Anaconda中创建一个专门用于本次天池练习赛的虚拟环境。          \n",
    "\n",
    ">$conda create -n py37_torch131 python=3.7      \n",
    "                                \n",
    "- 激活环境，并安装pytorch1.3.1\n",
    "                                     \n",
    ">$source activate py37_torch131                         \n",
    "\n",
    ">$conda install pytorch=1.3.1 torchvision cudatoolkit=10.0                     \n",
    "       \n",
    "       \n",
    "- 通过下面的命令一键安装所需其它依赖库     \n",
    "\n",
    ">$pip install jupyter tqdm opencv-python matplotlib pandas                                  \n",
    "       \n",
    "- 启动notebook，即可开始baseline代码的学习                  \n",
    "\n",
    ">$jupyter-notebook    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入常用的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1：定义读取图像的Dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 设置最长的字符长度为5个\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2：定义训练数据和验证数据的Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30000 30000\n10000 10000\n"
    }
   ],
   "source": [
    "train_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=800, #默认40 \n",
    "    shuffle=True, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")\n",
    "\n",
    "val_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    # transforms.Resize((60, 120)),\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=800, #默认40 \n",
    "    shuffle=False, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3：定义字符分类模型\n",
    "使用resnet18的模型作为特征提取模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "                \n",
    "        model_conv = models.resnet18(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 11)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "        self.fc3 = nn.Linear(512, 11)\n",
    "        self.fc4 = nn.Linear(512, 11)\n",
    "        self.fc5 = nn.Linear(512, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4：定义训练、验证和预测模块 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        c0, c1, c2, c3, c4 = model(input)\n",
    "        target = target.long() #添加\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "                criterion(c1, target[:, 1]) + \\\n",
    "                criterion(c2, target[:, 2]) + \\\n",
    "                criterion(c3, target[:, 3]) + \\\n",
    "                criterion(c4, target[:, 4])\n",
    "        \n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if i % 100 == 0:\n",
    "            # print(loss.item())\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            target = target.long() #添加\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                    criterion(c1, target[:, 1]) + \\\n",
    "                    criterion(c2, target[:, 2]) + \\\n",
    "                    criterion(c3, target[:, 3]) + \\\n",
    "                    criterion(c4, target[:, 4])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    \n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                \n",
    "                c0, c1, c2, c3, c4 = model(input)\n",
    "                if use_cuda:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(), \n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(), \n",
    "                        c3.data.cpu().numpy(),\n",
    "                        c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(), \n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(), \n",
    "                        c3.data.numpy(),\n",
    "                        c4.data.numpy()], axis=1)\n",
    "                \n",
    "                test_pred.append(output)\n",
    "        \n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5：迭代训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 0, Train loss: 4.606284881892957 \t Val loss: 4.114817399245042\n0.1917\nEpoch: 1, Train loss: 2.320704547982467 \t Val loss: 3.465121636023888\n0.3224\nEpoch: 2, Train loss: 1.9032725064378035 \t Val loss: 3.177721408697275\n0.3787\nEpoch: 3, Train loss: 1.707814386016444 \t Val loss: 3.084074698961698\n0.4064\nEpoch: 4, Train loss: 1.5795258064019053 \t Val loss: 2.9795486560234656\n0.4259\nEpoch: 5, Train loss: 1.4917219939984774 \t Val loss: 3.0296392807593713\n0.4286\nEpoch: 6, Train loss: 1.4357515448018123 \t Val loss: 2.8741910457611084\n0.4608\nEpoch: 7, Train loss: 1.386231707899194 \t Val loss: 2.7199939764462986\n0.4883\nEpoch: 8, Train loss: 1.3359975187402022 \t Val loss: 2.6292074093451867\n0.5229\nEpoch: 9, Train loss: 1.3098824933955544 \t Val loss: 2.8126310201791616\n0.4643\nlearning rate:\t0.000200\nEpoch: 10, Train loss: 0.9757675371671978 \t Val loss: 2.17359183384822\n0.6134\nEpoch: 11, Train loss: 0.8033741602772161 \t Val loss: 2.282026822750385\n0.6031\nEpoch: 12, Train loss: 0.7325325765107807 \t Val loss: 2.3142984830416164\n0.6035\nlearning rate:\t0.000040\nEpoch: 13, Train loss: 0.6148699569074731 \t Val loss: 2.1982305416694055\n0.6366\nEpoch: 14, Train loss: 0.5516277261470494 \t Val loss: 2.2544497710007887\n0.6337\nEpoch: 15, Train loss: 0.5233694558080874 \t Val loss: 2.2706238673283505\n0.6355\nlearning rate:\t0.000008\nEpoch: 16, Train loss: 0.4877515827354632 \t Val loss: 2.2808052759904127\n0.6383\nEpoch: 17, Train loss: 0.4722644529844585 \t Val loss: 2.312325440920316\n0.6354\nlearning rate:\t0.000008\nEpoch: 18, Train loss: 0.4714224126778151 \t Val loss: 2.300881110704862\n0.6395\nEpoch: 19, Train loss: 0.4600151510615098 \t Val loss: 2.3392701148986816\n0.6371\n"
    }
   ],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "wd = 0.01\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=wd)\n",
    "best_loss = 1000.0\n",
    "best_acc = 0\n",
    "\n",
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "loss_increase_num = 0 # 用于调节学习率\n",
    "val_loss_last = best_loss # 上一次的验证集误差\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    \n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader, model, 5)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "        val_predict_label[:, 44:55].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "    \n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print(val_char_acc)\n",
    "    \n",
    "    # 修改学习率，如果验证集的loss出现上升\n",
    "    if epoch != 1 and val_loss > val_loss_last:\n",
    "        loss_increase_num += 1\n",
    "        if loss_increase_num == 2: # 出现上升两次\n",
    "            loss_increase_num = 0\n",
    "            if lr > 0.000011: # 不能过小\n",
    "                lr = lr * 0.2\n",
    "            print('learning rate:\\t%f'%lr)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=wd)\n",
    "\n",
    "    val_loss_last = val_loss\n",
    "\n",
    "    # 记录下验证集精度，保存两个，一个loss最优，一个acc最优\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//model_v4_val_loss.pt')\n",
    "    if val_char_acc > best_acc:\n",
    "        best_acc = val_char_acc\n",
    "        torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//model_v4_val_acc.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练两个2 Epoch后，输出的训练日志为：\n",
    "         \n",
    "Epoch: 0, Train loss: 3.1 \t Val loss: 3.4 验证集精度：0.3439       \n",
    "Epoch: 1, Train loss: 2.1 \t Val loss: 2.9 验证集精度：0.4346\n",
    "\n",
    "* Quadro P1000: batch_size=40 epoch=2 需要6min15s GPU-util:50%-60%\n",
    "* Quadro P1000: batch_size=200 epoch=2 需要4min59s GPU-util:60%-98%\n",
    "* i7-8850H: batch_size=40 epoch=2 需要47min30s CPU-util:50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../../data/Datawhale-Tianchi-CV_SVHN//model_v4_val_epoch20.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤6：对测试集样本进行预测，生成提交文件          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存的最好的模型载入\n",
    "# model.load_state_dict(torch.load('../../data/Datawhale-Tianchi-CV_SVHN//model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_test_a/*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=0, # win下num_works改为0,linux=10\n",
    ")\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "    test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_submit = pd.read_csv('../../data/Datawhale-Tianchi-CV_SVHN/mchar_sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('../../data/Datawhale-Tianchi-CV_SVHN/resnet18_baseline_v1lr_epoch20.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练完成2个Epoch后，模型在测试集上的成绩应该在0.33左右。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitbb390991d78f474893554122ad84e457"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2 数据读取与数据扩增"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用【定长字符识别】思路来构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据读取与数据扩增\n",
    "* Python和Pytorch中图像读取    \n",
    "* 扩增方法和Pytorch读取赛题数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 图像读取\n",
    "比较常见的有Pillow和OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Pillow\n",
    "\n",
    "Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。\n",
    "\n",
    "|效果|  代码 |\n",
    "|----|-----|\n",
    "|![IMG](IMG/Task02/Pillow读取原图.png)   |   from PIL import Image<br># 导入Pillow库<br> <br> # 读取图片<br>im =Image.open(cat.jpg') |\n",
    "|![IMG](IMG/Task02/Pillow模糊原图.png)   |   from PIL import Image, ImageFilter<br>im = Image.open('cat.jpg')<br> # 应用模糊滤镜:<br>im2 = im.filter(ImageFilter.BLUR)<br>im2.save('blur.jpg', 'jpeg') |\n",
    "|![IMG](IMG/Task02/Pillow缩放原图.png)   |   from PIL import Image<br># 打开一个jpg图像文件，注意是当前路径:<br> im = Image.open('cat.jpg')<br>im.thumbnail((w//2, h//2))<br>im.save('thumbnail.jpg', 'jpeg') |\n",
    "\n",
    "当然上面只演示了Pillow最基础的操作，Pillow还有很多图像操作，是图像处理的必备库。       \n",
    "Pillow的官方文档：https://pillow.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 OpenCV\n",
    "\n",
    "OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。 \n",
    "\n",
    "安装cv2: pip install opencv-python\n",
    "\n",
    "|效果|  代码 |\n",
    "|----|-----|\n",
    "|![IMG](IMG/Task02/Pillow读取原图.png)   |  import cv2<br># 导入Opencv库<br>img = cv2.imread('cat.jpg')<br># Opencv默认颜色通道顺序是BRG，转换一下<br>img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  |\n",
    "|![IMG](IMG/Task02/opencv灰度图.png)   |  import cv2<br># 导入Opencv库<br>img = cv2.imread('cat.jpg')<br>img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br># 转换为灰度图  |\n",
    "|![IMG](IMG/Task02/opencv边缘检测.png)   |  import cv2<br># 导入Opencv库<br>img = cv2.imread('cat.jpg')<br>img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br># 转换为灰度图<br># Canny边缘检测<br>edges = cv2.Canny(img, 30, 70)<br>cv2.imwrite('canny.jpg', edges)  |\n",
    "\n",
    "       \n",
    "OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。       \n",
    "OpenCV官网：https://opencv.org/       \n",
    "OpenCV Github：https://github.com/opencv/opencv      \n",
    "OpenCV 扩展算法库：https://github.com/opencv/opencv_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据扩增方法          \n",
    "\n",
    "在赛题中我们需要对的图像进行字符识别，因此需要我们完成的数据的读取操作，同时也需要完成数据扩增（Data Augmentation）操作。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 数据扩增介绍      \n",
    "在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。\n",
    "      \n",
    "![IMG](IMG/Task02/数据扩增.png)\n",
    "          \n",
    "- #### 数据扩增为什么有用？      \n",
    "在深度学习模型的训练过程中，数据扩增是必不可少的环节。现有深度学习的参数非常多，一般的模型可训练的参数量基本上都是万到百万级别，而训练集样本的数量很难有这么多。       \n",
    "其次数据扩增可以扩展样本空间，假设现在的分类模型需要对汽车进行分类，左边的是汽车A，右边为汽车B。如果不使用任何数据扩增方法，深度学习模型会从汽车车头的角度来进行判别，而不是汽车具体的区别。     \n",
    "      \n",
    "![IMG](IMG/Task02/数据扩增car.png)   \n",
    "                   \n",
    "- #### 有哪些数据扩增方法？            \n",
    "数据扩增方法有很多：从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。        \n",
    "对于图像分类，数据扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数据扩增会改变像素标签。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 常见的数据扩增方法     \n",
    "在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。         \n",
    "\n",
    "以torchvision为例，常见的数据扩增方法包括：\n",
    "\n",
    "- transforms.CenterCrop      对图片中心进行裁剪      \n",
    "- transforms.ColorJitter      对图像颜色的对比度、饱和度和零度进行变换      \n",
    "- transforms.FiveCrop     对图像四个角和中心进行裁剪得到五分图像     \n",
    "- transforms.Grayscale      对图像进行灰度变换    \n",
    "- transforms.Pad        使用固定值进行像素填充     \n",
    "- transforms.RandomAffine      随机仿射变换    \n",
    "- transforms.RandomCrop      随机区域裁剪     \n",
    "- transforms.RandomHorizontalFlip      随机水平翻转     \n",
    "- transforms.RandomRotation     随机旋转     \n",
    "- transforms.RandomVerticalFlip     随机垂直翻转   \n",
    "      \n",
    " ![IMG](IMG/Task02/数据扩增示例.png)    \n",
    "       \n",
    "在本次赛题中，赛题任务是需要对图像中的字符进行识别，因此对于字符图片并不能进行翻转操作。比如字符6经过水平翻转就变成了字符9，会改变字符原本的含义。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 常用的数据扩增库     \n",
    "- #### torchvision      \n",
    "https://github.com/pytorch/vision      \n",
    "pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；       \n",
    "        \n",
    "- #### imgaug         \n",
    "https://github.com/aleju/imgaug      \n",
    "imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；      \n",
    "       \n",
    "- #### albumentations       \n",
    "https://albumentations.readthedocs.io      \n",
    "是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Pytorch读取数据\n",
    "\n",
    "本次赛题使用Pytorch框架讲解具体的解决方案，接下来将是解决赛题的第一步使用Pytorch读取赛题数据。  \n",
    "     \n",
    "在Pytorch中数据是通过Dataset进行封装，并通过DataLoder进行并行读取。所以我们只需要重载一下数据读取的逻辑就可以完成数据的读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index): # 可以让对象实现迭代功能\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 原始SVHN中类别10为数字0\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10] # 填充到定长，空为10\n",
    "        \n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self): #len(SVHNDataset)\n",
    "        return len(self.img_path)\n",
    "\n",
    "train_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train/*.png') #glob.glob 返回所有匹配的文件路径列表。\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "\n",
    "data = SVHNDataset(train_path, train_label,\n",
    "          transforms.Compose([\n",
    "              # 缩放到固定尺寸\n",
    "              transforms.Resize((64, 128)),\n",
    "\n",
    "              # 随机颜色变换\n",
    "              transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "\n",
    "              # 加入随机旋转\n",
    "              transforms.RandomRotation(5),\n",
    "\n",
    "              # 将图片转换为pytorch 的tesntor\n",
    "              # transforms.ToTensor(),\n",
    "\n",
    "              # 对图像像素进行归一化\n",
    "              # transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<PIL.Image.Image image mode=RGB size=128x64 at 0x1E40C6BCF70>,\n tensor([ 2,  3, 10, 10, 10], dtype=torch.int32))"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 1,  9, 10, 10, 10], dtype=torch.int32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "data[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上述代码，可以将赛题的图像数据和对应标签进行读取，在读取过程中的进行数据扩增，效果如下所示： \n",
    "      \n",
    "|1|2|3|      \n",
    "|----|-----|------|          \n",
    "|![IMG](IMG/Task02/23.png) | ![IMG](IMG/Task02/23_1.png)| ![IMG](IMG/Task02/23_2.png)|\n",
    "|![IMG](IMG/Task02/144_1.png) | ![IMG](IMG/Task02/144_2.png)| ![IMG](IMG/Task02/144_3.png)|\n",
    "      \n",
    "接下来我们将在定义好的Dataset基础上构建DataLoder\n",
    "                 \n",
    "- Dataset：对数据集的封装，提供索引方式的对数据样本进行读取      \n",
    "- DataLoder：对Dataset进行封装，提供批量读取的迭代读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入DataLoder后，数据读取代码改为如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2\ntorch.Size([10, 3, 64, 128])\ntorch.Size([10, 5])\ntensor([[ 1,  9, 10, 10, 10],\n        [ 2,  3, 10, 10, 10],\n        [ 2,  5, 10, 10, 10],\n        [ 9,  3, 10, 10, 10],\n        [ 3,  1, 10, 10, 10],\n        [ 3,  3, 10, 10, 10],\n        [ 2,  8, 10, 10, 10],\n        [ 7,  4,  4, 10, 10],\n        [ 1,  2,  8, 10, 10],\n        [ 1,  6, 10, 10, 10]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 原始SVHN中类别10为数字0\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        \n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "train_path = glob.glob('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        SVHNDataset(train_path, train_label,\n",
    "                   transforms.Compose([\n",
    "                       transforms.Resize((64, 128)),\n",
    "                       transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                       transforms.RandomRotation(5),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])), \n",
    "    batch_size=10, # 每批样本个数\n",
    "    shuffle=False, # 是否打乱顺序\n",
    "    num_workers=0, # 读取的线程个数 # win=0 linux可以设置为10\n",
    ")\n",
    "\n",
    "for data in train_loader:\n",
    "    print(len(data))\n",
    "    # print(data[0])\n",
    "    print(data[0].size())\n",
    "    print(data[1].size())\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1, 2, 2, 9, 3, 3, 2, 7, 1, 1], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "print(data[1][:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为： \n",
    "\n",
    "                ``` torch.Size([10, 3, 64, 128]), torch.Size([10, 6]) ```          \n",
    "                \n",
    "前者为图像文件，为batchsize \\* chanel \\* height \\* width次序；后者为字符标签。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 字符label长度统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2    16262\n3     7813\n1     4636\n4     1280\n5        8\n6        1\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# 训练集字符长度统计\n",
    "train_label_len = [len(x) for x in train_label]\n",
    "pd.Series(train_label_len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2    0.542067\n3    0.260433\n1    0.154533\n4    0.042667\n5    0.000267\n6    0.000033\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pd.Series(train_label_len).value_counts()/len(train_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_json = json.load(open('../../data/Datawhale-Tianchi-CV_SVHN/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2    6393\n1    1918\n3    1569\n4     118\n5       2\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# 验证集字符长度统计\n",
    "val_label_len = [len(x) for x in val_label]\n",
    "pd.Series(val_label_len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2    0.6393\n1    0.1918\n3    0.1569\n4    0.0118\n5    0.0002\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "pd.Series(val_label_len).value_counts()/len(val_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bitbb390991d78f474893554122ad84e457",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}